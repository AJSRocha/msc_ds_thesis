---
title: "Proposta para trabalho a desenvolver para tese de mestrado em Ciência de Dados"
author: "Alberto Rocha, 200202358"
date: '2022-09-21'
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning =F)
```

# Setup

```{r}
library(forecast)
#library(ggfortify); 
library(gridExtra); #library(ggplotify)
library(gridGraphics)
library(tidyverse)
library(wesanderson)
library(dplyr)
library(xtable)
# install.packages('tweedie')
library(tweedie)
library(emmeans)
library(statmod)
library(lsmeans)

#atencao ao carregar o ggfortify e o ggplotify, eles sao incompativeis com os metodos de autoplot e autolayer

#library(CatDyn)
```

# Colour Schemes

```{r}
col_mis_w  = wes_palette('Zissou1',4)[4]
col_otb_w  = wes_palette('Zissou1',4)[3]
col_mis_s  = wes_palette('Zissou1',4)[1]
col_otb_s  = wes_palette('Zissou1',4)[2]
```


# Importar dados

## Vendas-Dia

Carregar vendas dia:

```{r, include = F}
# source('scripts/vd_import.R')
# load('data/initial_data_occ.Rdata')
load('data/initial_data_occ_sumario.Rdata')
```

Função auxiliar que agrupa vd em regioes (S vs W) e cria as unidades temporais necessarias para as secçoes seguintes:

```{r, include = F}

arranjador = function(df){
  temp = df %>%
    mutate(regiao = case_when(as.character(zona) %in% 
                              c('27.9.a.c.n', '27.9.a.c.s') ~ 'Costa Ocidental',
                            as.character(zona) == '27.9.a.s.a' ~ 'Costa Sul',
                            T ~ as.character(zona)),
           semana = lubridate::isoweek(IDATVEND),
           dia = weekdays(IDATVEND))
  return(temp)
}

```

Executa transformação do dataframe

```{r}
df = arranjador(vd)

# df %>% select(year_sale, IDATVEND, semana, fishing_season, semana_fs) %>% View()
# grava df no data

# df %>% 
#   select(IDATVEND, year_sale, fishing_season, semana, semana_fs) %>%
#   mutate(teste = semana_fs - semana) %>% View

# temp = df %>% 
#   select(IDATVEND, year_sale, fishing_season, semana, semana_fs) %>%
#   mutate(teste = semana_fs - semana) 

# save(df, file = 'data/initial_data_occ_df.Rdata')
# load('data/initial_data_occ_df.Rdata')
# df$ratio = df$QVENDA / df$QVENDA_total
```

# Cria DataFrames agregados com esforço calculado

```{r}

a = Sys.time()
frota = data.frame(year_sale = character(0),IEMBARCA = character(0), polvicidade = numeric(0), catch = numeric(0))
for(ano in unique(df$year_sale)){
  temp = df %>% 
    filter(year_sale == ano) %>% 
    group_by(year_sale, IEMBARCA) %>% 
    summarise(polvicidade = mean(ratio),
              catch = sum(QVENDA))
  
  frota = rbind(frota, temp)
  }

b =Sys.time()
preproc_ratios = b-a #Time difference of 1.617802 hours

# save(frota, file = 'data/frota_ref.Rdata')
load('data/frota_ref.Rdata')

a = Sys.time()
df = df %>% left_join(
  .,
  frota %>% 
    mutate(ref = ifelse(polvicidade > 0.5, T, F)) %>% 
    select(year_sale, IEMBARCA, ref),
  by = c('year_sale', 'IEMBARCA'))

b = Sys.time() #Time difference of 1.227311 mins

preproc_add_frota_ref = b-a 
```

# Plot das proporcoes de OCC em cada viagem

```{r}
fig =
df %>% 
  # mutate(grupo = paste(regiao, EGRUPART)) %>% 
  # head(10000) %>%
   mutate(regiao = case_when(regiao == 'Costa Ocidental' ~ '1-Western Coast',
                            T ~ '2-Southern Coast'),
         EGRUPART = case_when(EGRUPART == 'MIS_MIS' ~ '1-Polyvalent',
                            T ~ '2-Bottom Trawl'),
         fill = paste(regiao, EGRUPART),) %>%
  # filter(EGRUPART %in% c('MIS_MIS', 'OTB')) %>%
  ggplot() + 
  geom_histogram(aes(x = ratio, fill = fill)) + 
  theme_light() + 
  scale_fill_manual(values = c(col_mis_w,  col_otb_w,col_mis_s, col_otb_s)) + 
  facet_wrap(fill ~ ., ncol = 2, scales = 'free_y') +
  theme(legend.position = 'none') + 
  labs(x = 'octopus proportion', y = 'trips') 


ggsave(fig, dpi = 300, width = 20, height = 20, units = 'cm', filename = 'plots/res_preprop_ratios.png')
```

# Limpeza 

```{r}
a = Sys.time()
df =
df %>% group_by(IEMBARCA) %>%
mutate(EGRUPART = ifelse(is.na(EGRUPART),
                           sort(EGRUPART, decreasing = F)[1],
                           EGRUPART)) %>%
  ungroup()
b = Sys.time()

df[is.na(df$EGRUPART),]$EGRUPART = "MIS_MIS"
summary(df$EGRUPART %>% factor)

save(df, df_effort, frota_cerco, file = 'data/initial_data_occ_df_limpo_ps.Rdata')

frota_cerco = unique(df$IEMBARCA[df$EGRUPART == 'PS'])    
```

```{r}
df_int= df %>%
  filter(!IEMBARCA %in% frota_cerco) %>% 
  filter(!(EGRUPART == 'MIS_MIS' & !ref)) %>%
  filter(regiao != 'O')

df_effort= df_int %>%
  group_by(IEMBARCA, EGRUPART, regiao, year_sale) %>% 
  summarise(QVENDA_s = sum(QVENDA),
            esforco = length(IDATVEND)) %>% 
  mutate(lpue = QVENDA_s/esforco)

save(df, df_effort, df_int, frota_cerco, file = 'data/initial_data_occ_df_limpo_ps.Rdata')
```

# Começar aqui

```{r}
load(file = 'data/initial_data_occ_df_limpo_ps.Rdata')
```

```{r}
sum(df_effort$esforco)
```

# Plot esforco por ano

```{r}
fig = 
df_effort %>% 
  mutate(fill = paste(regiao, EGRUPART),
         regiao = case_when(regiao == 'Costa Ocidental' ~ '1-Western Coast',
                            T ~ '2-Southern Coast'),
         EGRUPART = case_when(EGRUPART == 'MIS_MIS' ~ '1-Polyvalent',
                            T ~ '2-Bottom Trawl')) %>% 
  ggplot() + 
  geom_bar(aes(x = year_sale,
               y = esforco,
               fill = fill),
           stat = 'identity') + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = 'none') +
  labs(x = 'Year', y = 'Trips') + 
  scale_fill_manual(values = c(col_mis_w,  col_otb_w,col_mis_s, col_otb_s)) + 
  facet_grid(regiao ~ EGRUPART)

ggsave(fig, dpi = 300, width = 20, height = 20, units = 'cm', filename = 'plots/res_preprop_effort_year.png')
```

# Estandardiza o esforço

- CPUE nominal: simplesmente captura sobre unidade de esforço
  lpue anual = media de captura de cada viagem/anual
  esforço = nº de viagens
  
- CPUE standardizado: Esforco padronizado a uma frota de referencia
(como?)


```{r}

```


```{r}
a = Sys.time()
out = tweedie.profile(QVENDA ~ EGRUPART + year_sale + month_sale + regiao + Power.Main,
                      p.vec=seq(1.01, 1.9, length=9), link.power=0,
                      data=df_int,
                      method="interpolation",
                      do.ci=TRUE, do.smooth=TRUE, do.plot=TRUE, phi.method="saddlepoint")
b = Sys.time()

a = Sys.time()
std = glm(QVENDA ~ EGRUPART + year_sale + month_sale + regiao + Power.Main,
          data = df_int, family = tweedie(var.power = out$p.max, link.power = 0))
b = Sys.time() #59.48 segundos
b-a


ls.Model = lsmeans(std,  "year_sale")
teste <- summary(ls.Model)$lsmeans[c("lsmean", "lower.CL", "upper.CL")]

ls.Model = data.frame(ls.Model)
lsmean<-scale(exp(ls.Model$lsmean),center = F,scale=T)
SE<-scale(exp(ls.Model$SE),center = F,scale=T)
asymp.LCL<-scale(exp(ls.Model$asymp.LCL),center = F,scale=T)
asymp.UCL<-scale(exp(ls.Model$asymp.UCL),center = F,scale=T)

```


```{r}
# std = glm(lpue ~ EGRUPART + year_sale + regiao, data = df_effort, family = 'gaussian')

df_effort %>%
  ungroup() %>% 
  # mutate(lpue_std = std$fitted.values) %>%
  group_by(EGRUPART, regiao, year_sale) %>% 
  summarise(lpue = mean(lpue),
            lpue_std = mean(lpue_std)) %>%
  filter(regiao %in% c('Costa Ocidental', 'Costa Sul')) %>% 
ggplot() + 
  geom_line(aes(x = year_sale, y = lpue, group = 1)) +
  # geom_line(aes(x = year_sale, y = lpue_std, group = 1), col = 'red') +
  facet_grid(regiao ~  EGRUPART)
```

# Plot das series e lpue

```{r}
fig = 
df_effort %>%
  ungroup() %>% 
  # mutate(lpue_std = std$fitted.values) %>% 
  mutate(fill = paste(regiao, EGRUPART),
         regiao = case_when(regiao == 'Costa Ocidental' ~ '1-Western Coast',
                            T ~ '2-Southern Coast'),
         EGRUPART = case_when(EGRUPART == 'MIS_MIS' ~ '1-Polyvalent',
                            T ~ '2-Bottom Trawl')) %>% 
  group_by(EGRUPART, regiao, year_sale, fill) %>% 
  summarise(QVENDA = sum(QVENDA_s),
            lpue = mean(lpue),
            lpue_std = ls.Model) %>% 
  ggplot() +
  geom_line(aes(x = year_sale,
                y = QVENDA,
                group = 1,
                color = fill)) + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90),
        legend.position = 'none') +
  labs(x = 'Year', y = 'landings (kg)') + 
  scale_color_manual(values = c(col_mis_w,  col_otb_w,col_mis_s, col_otb_s)) + 
  facet_grid(regiao ~ EGRUPART, scales = 'free_y')

fig
```



# Cria os objectos

```{r}
a = Sys.time()
df_y_MIS_W = df_effort %>% 
  filter(regiao == 'Costa Ocidental') %>%
  filter(EGRUPART == 'MIS_MIS') %>% 
  # filter(ref) %>% 
  # group_by(IEMBARCA, year_sale) %>% 
  # summarise(QVENDA_s = sum(QVENDA),
  #           esforco = length(IDATVEND)) %>%
  group_by(year_sale) %>% 
  summarise(catch = sum(QVENDA_s),
            effort = sum(esforco),
            lpue_y = mean(lpue),
            lpue_med = median(lpue),
            sd = sd(lpue))


df_y_OTB_W = df_effort %>% 
  filter(regiao == 'Costa Ocidental') %>%
  filter(EGRUPART == 'OTB') %>% 
  # filter(ref) %>% 
  # group_by(IEMBARCA, year_sale) %>% 
  # summarise(QVENDA_s = sum(QVENDA),
  #           esforco = length(IDATVEND)) %>%
  group_by(year_sale) %>% 
  summarise(catch = sum(QVENDA_s),
            effort = sum(esforco),
            lpue_y = mean(lpue),
            lpue_med = median(lpue),
            sd = sd(lpue))  

df_y_MIS_S = df_effort %>% 
  filter(regiao == 'Costa Sul') %>%
  filter(EGRUPART == 'MIS') %>% 
  # filter(ref) %>% 
  # group_by(IEMBARCA, year_sale) %>% 
  # summarise(QVENDA_s = sum(QVENDA),
  #           esforco = length(IDATVEND)) %>%
  group_by(year_sale) %>% 
  summarise(catch = sum(QVENDA_s),
            effort = sum(esforco),
            lpue_y = mean(lpue),
            lpue_med = median(lpue),
            sd = sd(lpue))

df_y_OTB_S = df_effort %>% 
  filter(regiao == 'Costa Sul') %>%
  filter(EGRUPART == 'OTB') %>% 
  # filter(ref) %>% 
  # group_by(IEMBARCA, year_sale) %>% 
  # summarise(QVENDA_s = sum(QVENDA),
  #           esforco = length(IDATVEND)) %>%
  group_by(year_sale) %>% 
  summarise(catch = sum(QVENDA_s),
            effort = sum(esforco),
            lpue_y = mean(lpue),
            lpue_med = median(lpue),
            sd = sd(lpue)) 

# df_y_MIS_W = df %>% 
#   filter(regiao == 'Costa Ocidental') %>%
#   filter(EGRUPART == 'MIS_MIS') %>% 
#   filter(QVENDA > 0) %>% 
#   group_by(IEMBARCA, year_sale) %>% 
#   summarise(QVENDA_s = sum(QVENDA),
#             effort_s = n_distinct(IDATVEND)) %>% 
#   group_by(year_sale) %>% 
#   summarise(QVENDA = sum(QVENDA_s),
#             effort = sum(effort_s))


# df_y_OTB_W = df %>% 
#   filter(regiao == 'Costa Ocidental') %>%
#   filter(EGRUPART == 'OTB') %>% 
#   filter(QVENDA > 0) %>% 
#   group_by(IEMBARCA, year_sale) %>% 
#   summarise(QVENDA_s = sum(QVENDA),
#             effort_s = n_distinct(IDATVEND)) %>% 
#   group_by(year_sale) %>% 
#   summarise(QVENDA = sum(QVENDA_s),
#             effort = sum(effort_s))
# 
# df_y_MIS_S = df %>% 
#   filter(regiao == 'Costa Sul') %>%
#   filter(EGRUPART == 'MIS_MIS') %>% 
#   filter(QVENDA > 0) %>% 
#   group_by(IEMBARCA, year_sale) %>% 
#   summarise(QVENDA_s = sum(QVENDA),
#             effort_s = n_distinct(IDATVEND)) %>% 
#   group_by(year_sale) %>% 
#   summarise(QVENDA = sum(QVENDA_s),
#             effort = sum(effort_s))
# 
# df_y_OTB_S = df %>% 
#   filter(regiao == 'Costa Sul') %>%
#   filter(EGRUPART == 'OTB') %>% 
#   filter(QVENDA > 0) %>% 
#   group_by(IEMBARCA, year_sale) %>% 
#   summarise(QVENDA_s = sum(QVENDA),
#             effort_s = n_distinct(IDATVEND)) %>% 
#   group_by(year_sale) %>% 
#   summarise(QVENDA = sum(QVENDA_s),
#             effort = sum(effort_s))

b = Sys.time()
df_effort_calc = b-a
```

```{r}
df_y_MIS_W %>% 
ggplot() +
  geom_line(aes(x = year_sale,
                y = lpue_y/max(lpue_y),
                group = 1), col = 'blue') + 
  geom_line(aes(x = year_sale,
                y = catch/max(catch),
                group = 1),
            color = 'red') + 
  geom_line(aes(x = year_sale,
                y = lpue_med/max(lpue_med),
                group = 1), color = 'green')
```


## Dados Biologicos

186 One important shortcoming of the data was that the biological sampling of mean weight 187 did not occur in all weeks of the 19 seasons and yet individual weight data are necessary 188 to transform from catch in weight to catch in numbers in all weeks (Supplementary Table 189 SM1). As in previous cases with missing biological sampling (Roa-Ureta, 2015; Roa-Ureta 190 et al., 2019, 2020) the missing mean individual weight was replaced with predictions from 191 an accessory model fit with the available data. First, we fitted a simple model of mean 192 weight change through the weeks of the year with a cubic spline smoother, function 193 loess in R 3.6.1 (R Core Team, 2019). Little inter-annual variability was observed in 194 the seasonal pattern of the mean individual weight (Fig. 2) and this pattern was similar 195 to results presented in Fern ́andez-Rueda and Garc ́ıa-Fl ́ orez (2007). Thus we used the 196 pooled data from all 19 seasons to estimate the weekly mean weight model (n=275). 197 In the fit of this accessory model we created a predictor variable spanning the range of 198 week numbers in a year (1 to 53), then we used the data to fit the smoother with a span 199 parameter equal to 1 (equivalent to using the data from all weeks to predict the model 200 at each week), and finally to predict the expected mean weight and its standard error for 201 all weeks within a season (Supplementary Fig. SM2). Secondly, we predicted the mean 202 weight for each week in each season from a truncated normal distribution defined by the 203 predicted weekly mean weight ± 2 standard errors using R package Runuran (Leydold 204 and H ̈ ormann, 2019) (Supplementary Fig. SM2). In this manner we obtained a complete 205 vector of mean weight matching the catch and effort data while introducing noise due to 206 sampling variation in the biological data.

```{r}

semanador_fs_bio = function(x){
  mod = ifelse(as.numeric(as.character(x$ano)) == as.numeric(as.character(x$fishing_season)),
               0,
               1)
  week_start =paste0(as.numeric(as.character(x$ano))-mod, '-10-01') %>% 
    as.POSIXct(format = '%Y-%m-%d')
    res = (difftime(x$data_venda, week_start, units = 'days')/7 +1) %>% trunc()
    return(res)
  }

arranjador_bio = function(df){
  temp = df %>%
    mutate(regiao = case_when(as.character(regiao) %in% 
                              c('NW', 'SW') ~ 'Costa Ocidental',
                            as.character(regiao) == 'Sul' ~ 'Costa Sul',
                            T ~ as.character(regiao)),
          
          fishing_season = case_when(trim %in% c('4') ~
                                       as.numeric(as.character(ano)),
                                       T ~ as.numeric(as.character(ano)) - 1))
  return(temp)
}

# dados 1997 - 2016
bio_sic = read.csv('data/occ_20092016_cmp.csv')

bio_xxx = bio_sic %>% 
  mutate(ano = substr(DATA_AM, 7, 10),
         data_venda = as.POSIXct(DATA_AM, format = '%d-%m-%Y'),
         id_caixa = ID_AMOSTRA,
         regiao = case_when(REGIAO == 'S' ~ 'Costa Sul',
                            T ~ 'Costa Ocidental'),
         fishing_season = case_when(substr(DATA_AM, 4,5) %in%
                                      c('10', '11', '12') ~ as.numeric(ano),
                                    T ~ as.numeric(ano) - 1)) %>% 
  group_by(ano, data_venda, regiao, fishing_season, CAT, id_caixa) %>% 
  summarise(peso_am= unique(PESO_A_C) * 1000,
            n_am = unique(N_IND),
            mean_weight = peso_am/n_am)

bio_xxx$semana_fs = semanador_fs_bio(bio_xxx)
bio_xxx = bio_xxx %>% 
  ungroup() %>% 
  select(id_caixa, fishing_season, semana_fs, regiao, peso_am, n_am, mean_weight)

# bio_xxx = bio_xxx %>% 
#   group_by(ano, regiao, fishing_season, semana_fs) %>% 
#   summarise(peso_am = sum(peso_am),
#             n_am = sum(n_am),
#             mean_weight = peso_am/n_am)

load('data/nautilus_occ.Rdata')

bio_naut =
  arranjador_bio(bio_occ) %>%
  mutate(semana_fs = semanador_fs_bio(.)) %>% 
  # filter(fishing_season == '2021') %>% 
  # filter(regiao == 'Costa Sul') %>% 
  filter(estrategia_amostragem == 'Concurrent Sampling') %>% 
  group_by(id_caixa, fishing_season, semana_fs, regiao) %>% 
  summarise(peso_am = sum(peso_total),
            n_am = length(peso_total),
            mean_weight = peso_am/n_am)

bio = rbind(bio_xxx, bio_naut)
temp = bio %>% filter (fishing_season %in% c(2008:2022)) %>% 
  filter(mean_weight < 6000 & mean_weight > 100) %>% 
  mutate(fishing_season = factor(fishing_season))


# modelar peso medio

media = 
temp %>% group_by(semana_fs, regiao) %>% 
  summarise(avg_w = mean(mean_weight, na.rm = T),
            sd_w = sd(mean_weight, na.rm = T))

temp %>% 
  ggplot() + 
  geom_point(aes(x = semana_fs,
                 y = mean_weight,
                 color = fishing_season)) + 
  geom_line(aes(x = media$semana_fs,
                y = media$avg_w,
                group = media$regiao))

media %>% 
  ggplot() + 
   geom_line(aes(x = media$semana_fs,
                y = media$avg_w,
                group = media$regiao,
                color = media$regiao)) + 
     geom_line(aes(x = media$semana_fs,
                y = media$avg_w + sd_w,
                group = media$regiao,
                color = media$regiao))


mw_glm = glm(mean_weight ~ semana_fs + regiao,
             data = temp,
             family = 'gaussian')

temp$pred = predict(mw_glm, temp)

temp %>% 
  ggplot() + 
  geom_point(aes(x = semana_fs,
                y = pred,
                group = regiao,
                color = regiao))

temp %>% 
  ggplot() + 
  geom_point(aes(x = semana_fs,
                 y = mean_weight,
                 color = fishing_season)) +
    geom_line(aes(x = semana_fs,
                y = pred,
                group = regiao,
                color = regiao))
 
```


## Outputs

Exporta os objectos de forma a serem usados na app shiny

```{r}
save(ts_m_S, ts_m_W,
     ts_fs_S, ts_fs_W,
     ts_y_S, ts_y_W,
     ts_q_S, ts_q_W,
     ts_w_S, ts_w_W,
     file = 'app/data/box_jenkins.Rdata')
```

# Indices de esforço

* Dias de Pesca Estandardizados

* Metodologia Pereira - Lourenço

* Numero de embarcações activas (Roa-Ureta)

# Modelos

## Metodologia de Box - Jenkins

## CMSY++

## JABBA

## SPiCT

## CatDyn

Modelo Ruben_Roa
data collection by each fishing season:
-	daily catch in weight
-	fishing effort measured as the number of boats operating on any single day.
-	biological samples to provide data of mean individual weight in the catch to transform catch in weight to catch in numbers. 
-	raw data were aggregated into weekly time-steps to fit intra-annual generalized depletion models to each season’s data. 

Weekly aggregation is problematic due to irregularity of week intervals resulting from the varying lenght of the 53rd week, a problem compounded by the leap years. Therefore, a custom grouping and slicing of the data is necessary

**Effort** is measured as the number of boats operating on any single day.

* It is hard to define correctly whether any vessel, in a given day, is operating with octopus-targetting fishing gear. Because, in the polyvalent metiers, octopus is seldom a bycatch, there is an underlying assumption that vessels who landed octopus on any given day are a good indicator for the total of vessels who attempted to fish for octopus.

* We aggregate effort on a given week by summing. As per the Asturias paper, "we grouped the raw data into weekly time steps to fit intra-annual generalized depletion models to each season’s data. Fishing effort was the total number of fishing days by all boats operating in any given week."

**Spikes** proposed on the 2019 paper are 2:

* Recruits grow enough to be available to the fishery (750g). This is plausible. *Positive*

* Spawning females retreat and become harder to fish. Also plausible. *Negative*


```{r}
ts_w_FS_S = df %>%
  filter(regiao %in% c('Costa Ocidental', 'Costa Sul')) %>% 
  filter(EGRUPART %in% c('MIS_MIS')) %>%
  filter(regiao == 'Costa Sul') %>% 
  group_by(IDATVEND, semana_fs, fishing_season, regiao) %>% 
  summarise(QVENDA = sum(QVENDA),
            effort = n_distinct(IEMBARCA)) %>% 
  group_by(semana_fs, fishing_season, regiao) %>% 
  summarise(QVENDA = sum(QVENDA),
            effort = sum(effort))
  

# ts_w_FS_W = df %>%
#   filter(regiao %in% c('Costa Ocidental', 'Costa Sul')) %>% 
#   filter(EGRUPART %in% c('MIS_MIS')) %>% 
#   group_by(semana_fs, fishing_season, regiao) %>% 
#   summarise(QVENDA = sum(QVENDA)) %>% 
#   filter(regiao == 'Costa Ocidental')
```


```{r}
library(CatDyn)

df_catdyn_s =
ts_w_FS_S %>%
  filter(fishing_season == '2021') %>% 
  left_join(.,
            media %>% 
              # mutate(fishing_season = factor(fishing_season)) %>% 
              filter(regiao == 'Costa Sul'),
            by = c('semana_fs' = 'semana_fs'))

df_catdyn_s = df_catdyn_s %>%
  ungroup() %>% 
  transmute(obscat = QVENDA,
            obseff = effort,
            mw = avg_w,
            week = semana_fs)

## Check contraste

df_catdyn_s %>% 
  ggplot() + 
  geom_line(aes(x = week,
                y = obscat))

occ_cat = as.CatDynData(x=df_catdyn_s,
                       step="week",
                       fleet.name="Artisanal-S",
                       coleff=2,
                       colcat=1,
                       colmbw=3,
                       unitseff="trips",
                       unitscat="kg",
                       unitsmbw="g",
                       nmult="mill",
                       season.dates=c(as.Date("2021-10-01"),
                                      as.Date("2022-09-25")))

plot.CatDynData(occ_cat,
                mark = T,
                offset = c(0,1,10),
                hem = 'N')

M         <- 1/53 #1/Time step
N0.ini    <- 10 #billions
P1.ini    <- 0.1 #billions
P2.ini    <- 0.05 #billions
k.ini     <- 0.1 #1/n of boats
alpha.ini <- 0.7 #adimensional
beta.ini  <- 0.6 #adimensional
P1 = 52
pars.ini  <- log(c(M,
                   N0.ini,
                   P1.ini,
                   k.ini,
                   alpha.ini,
                   beta.ini))

dates <- c(head(occ_cat$Data$`Artisanal-S`$time.step,1),
           P1,
           tail(occ_cat$Data$`Artisanal-S`$time.step,1))

occ.P2.ini <- catdynexp(x=occ_cat,
                               p=1,
                               par=pars.ini,
                               dates=dates,
                               distr="aplnormal")


CatDynFit(x = occ_cat,
          p=2,
          par=pars.ini,
          dates=dates,
          distr="aplnormal",
          method="spg",
          itnmax=10)

```

```{r}
## Check contraste

df_catdyn_s %>% 
  ggplot() + 
  geom_line(aes(x = week,
                y = obscat)) +
   geom_line(aes(x = week,
                y = obseff*100),
             color = 'red') + 
  theme_bw()
```







































